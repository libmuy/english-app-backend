[Script Info]
; Script generated by Aegisub 9706-cibuilds-20caaabc0
; http://www.aegisub.org/
Title: Default Aegisub file
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: None

[Aegisub Project Garbage]
Export Encoding: Unicode (UTF-8)
Audio File: part2.wav
Video Zoom Percent: 1.000000
Active Line: 6

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,48,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:11.02,Default,,0,0,0,,在上集节目中，我们使用Python计算了音频文件的梅尔频率倒谱系数（MFCCs），这些文件来自Google语音命令数据集。
Dialogue: 0,0:00:10.97,0:00:16.91,Default,,0,0,0,,我们还将这些特征和标签分成了训练集、验证集和测试集。
Dialogue: 0,0:00:16.91,0:00:19.39,Default,,0,0,0,,现在我们准备训练我们的神经网络。
Dialogue: 0,0:00:19.60,0:00:26.13,Default,,0,0,0,,当我们想到训练一个模型来识别命令词时，我们可能会想到让模型识别许多不同的词语中的一个。
Dialogue: 0,0:00:26.11,0:00:34.45,Default,,0,0,0,,因此，如果我们说“停”，我们的算法将计算该词的MFCCs，并将这些系数作为特征发送到我们的模型。
Dialogue: 0,0:00:34.45,0:00:42.92,Default,,0,0,0,,然后模型会根据这些特征做出预测，并告诉我们它认为我们在所有可能的唤醒词中说的是“停”。
Dialogue: 0,0:00:43.06,0:00:47.68,Default,,0,0,0,,虽然这在某些场景中可能有用，比如给机器人下达命令，
Dialogue: 0,0:00:47.62,0:00:52.99,Default,,0,0,0,,但计算所有不同词语的概率非常耗费计算资源。
Dialogue: 0,0:00:53.03,0:01:03.64,Default,,0,0,0,,由于我们只关心一个词，训练一个二分类器来识别这个词并将其他所有声音和词汇归为一个类别要容易得多。
Dialogue: 0,0:01:03.68,0:01:07.42,Default,,0,0,0,,我们的两个类别将是“停”和“不是停”。
Dialogue: 0,0:01:07.38,0:01:15.59,Default,,0,0,0,,使用模型进行预测时，将给出模型认为它识别出的MFCC特征中的词是“停”的概率。
Dialogue: 0,0:01:15.76,0:01:22.48,Default,,0,0,0,,如果该概率超过某个阈值，我们的程序将通过例如打开灯等方式作出相应的反应。
Dialogue: 0,0:01:22.57,0:01:30.58,Default,,0,0,0,,这意味着我们需要训练一个数学模型，将声音分类为说出的词是“停”或其他东西。
Dialogue: 0,0:01:30.64,0:01:33.35,Default,,0,0,0,,在一个新的笔记本中，让我们加载我们的模块。
Dialogue: 0,0:01:33.59,0:01:36.11,Default,,0,0,0,,我们需要使用OS模块来处理加载文件。
Dialogue: 0,0:01:36.10,0:01:40.36,Default,,0,0,0,,我们还需要从Keras中获取层和模型来构建我们的神经网络。
Dialogue: 0,0:01:40.48,0:01:44.55,Default,,0,0,0,,最后，我们需要NumPy来帮助我们处理矩阵和其他张量。
Dialogue: 0,0:01:44.60,0:01:50.72,Default,,0,0,0,,作为一个快速测试，让我们读取数据集中可用的词，去掉背景噪音。
Dialogue: 0,0:01:50.68,0:01:55.36,Default,,0,0,0,,接下来，我们将设置在上集节目中创建的特征集文件的路径。
Dialogue: 0,0:01:55.43,0:02:00.56,Default,,0,0,0,,另外，当我们完成时，我们希望将我们的神经网络模型保存到一个文件中，
Dialogue: 0,0:02:00.52,0:02:02.25,Default,,0,0,0,,我们将在这里设置文件名。
Dialogue: 0,0:02:02.26,0:02:04.94,Default,,0,0,0,,我们还将在这里定义我们的唤醒词。
Dialogue: 0,0:02:04.92,0:02:09.60,Default,,0,0,0,,注意，它必须是数据集中列出的可用目标词之一。
Dialogue: 0,0:02:09.77,0:02:14.70,Default,,0,0,0,,然后我们可以使用NumPy加载特征集文件并打印出可用的集合。
Dialogue: 0,0:02:14.75,0:02:18.09,Default,,0,0,0,,让我们将它们分配给一些变量以便于访问。
Dialogue: 0,0:02:18.21,0:02:22.57,Default,,0,0,0,,张量是按任意维度排列的数据集合。
Dialogue: 0,0:02:22.57,0:02:25.70,Default,,0,0,0,,矩阵只是一个二维张量。
Dialogue: 0,0:02:25.69,0:02:30.77,Default,,0,0,0,,像我们用MFCCs创建的灰度图像就是一个矩阵。
Dialogue: 0,0:02:30.85,0:02:37.29,Default,,0,0,0,,所以，如果我们有一个线性排列的矩阵集合，我们就创建了一个三维张量。
Dialogue: 0,0:02:37.28,0:02:43.75,Default,,0,0,0,,如果我们查看特征集的维度，可以看到第一维是该集合中的样本数量。
Dialogue: 0,0:02:43.73,0:02:49.59,Default,,0,0,0,,而其他两维是每个样本中系数的数量和系数集的数量。
Dialogue: 0,0:02:49.66,0:02:56.26,Default,,0,0,0,,如果我们查看标签集，可以看到它是一个对应于不同词汇的数字集合。
Dialogue: 0,0:02:56.38,0:03:00.43,Default,,0,0,0,,0是“向后”，1是“床”，2是“鸟”，等等。
Dialogue: 0,0:03:00.53,0:03:03.19,Default,,0,0,0,,我们不希望二分类器这样。
Dialogue: 0,0:03:03.18,0:03:11.03,Default,,0,0,0,,所以我们找到目标词“停”的索引，并使用NumPy的equal函数只保留“停”标签。
Dialogue: 0,0:03:11.09,0:03:18.47,Default,,0,0,0,,通常，该函数返回true和false，所以我们需要使用asType函数将它们转换为1和0。
Dialogue: 0,0:03:18.49,0:03:24.51,Default,,0,0,0,,我会将它们保留为64位浮点值，因为这似乎是它们最初存储的格式。
Dialogue: 0,0:03:24.51,0:03:30.54,Default,,0,0,0,,如果我们再看一次，可以看到“停”标签现在为1，其他所有标签为0。
Dialogue: 0,0:03:30.62,0:03:31.82,Default,,0,0,0,,这是难点。
Dialogue: 0,0:03:31.80,0:03:34.25,Default,,0,0,0,,在这个集合中1的数量不多。
Dialogue: 0,0:03:34.26,0:03:40.10,Default,,0,0,0,,事实上，我们可以看到验证集中只有约4%的标签为1。
Dialogue: 0,0:03:40.04,0:03:45.12,Default,,0,0,0,,这意味着如果模型只是告诉我们所有东西的答案都不是“停”，
Dialogue: 0,0:03:45.13,0:03:48.27,Default,,0,0,0,,它的正确率会超过95%。
Dialogue: 0,0:03:48.26,0:03:53.04,Default,,0,0,0,,所以我们需要做得比这更好，如果我们希望识别出有人说“停”。
Dialogue: 0,0:03:53.05,0:04:02.62,Default,,0,0,0,,卷积神经网络（通常缩写为ConvNet或CNN）似乎是图像分类最流行的方法之一。
Dialogue: 0,0:04:02.57,0:04:11.15,Default,,0,0,0,,老实说，我并不完全理解卷积神经网络的工作细节，但如果你想了解更多关于它们的知识，有很多很好的资源。
Dialogue: 0,0:04:11.15,0:04:13.20,Default,,0,0,0,,目前，我们只需要让它工作。
Dialogue: 0,0:04:13.32,0:04:21.51,Default,,0,0,0,,我在这个Geeks for Geeks教程中找到了一个简单的图像分类网络，它似乎给了我们不错的准确率，而且容易实现。
Dialogue: 0,0:04:21.70,0:04:23.98,Default,,0,0,0,,我们将从这个分类器开始。
Dialogue: 0,0:04:24.00,0:04:26.89,Default,,0,0,0,,你也可以尝试其他网络。
Dialogue: 0,0:04:26.93,0:04:31.67,Default,,0,0,0,,调整VGG16网络中的一些权重似乎也很流行。
Dialogue: 0,0:04:31.66,0:04:40.41,Default,,0,0,0,,让我们看看教程中的网络，了解一下其基本原理。卷积神经网络通常由两个不同部分组成。
Dialogue: 0,0:04:40.44,0:04:43.22,Default,,0,0,0,,第一部分是卷积层组。
Dialogue: 0,0:04:43.19,0:04:47.77,Default,,0,0,0,,这些层通过自动学习和提取图像特征来工作。
Dialogue: 0,0:04:47.85,0:04:55.00,Default,,0,0,0,,这些特征然后传递到一个全连接的神经网络，该网络试图根据提供的特征分类图像。
Dialogue: 0,0:04:54.99,0:04:59.23,Default,,0,0,0,,卷积集的第一部分由三个步骤组成。
Dialogue: 0,0:04:59.37,0:05:02.51,Default,,0,0,0,,第一步是实际的卷积操作。
Dialogue: 0,0:05:02.50,0:05:10.28,Default,,0,0,0,,它由移动窗口作为一种滤波器遍历整个图像来提取一些特征，例如检测边缘。
Dialogue: 0,0:05:10.38,0:05:18.53,Default,,0,0,0,,这种滑动窗口滤波器被称为内核，它在采样图像的一组像素时执行一些数学运算。
Dialogue: 0,0:05:18.62,0:05:21.96,Default,,0,0,0,,在这个例子中，窗口是2x2像素。
Dialogue: 0,0:05:22.02,0:05:27.91,Default,,0,0,0,,这个内核中使用的权重在每个节点上是不同的，并在训练期间自动更新。
Dialogue: 0,0:05:27.94,0:05:32.32,Default,,0,0,0,,在这个例子中，我们在第一个卷积层中有32个节点。
Dialogue: 0,0:05:32.31,0:05:40.26,Default,,0,0,0,,因此，我们最终得到了32个不同的滤波图像，它们为我们提供了一些图像中的细节，例如边缘和角落。
Dialogue: 0,0:05:40.29,0:05:46.96,Default,,0,0,0,,修正线性单元（ReLU）激活简单地将特征图中的所有负数设置为零。
Dialogue: 0,0:05:46.92,0:05:51.96,Default,,0,0,0,,它为节点增加了一定程度的非线性，这使我们能够训练模型。
Dialogue: 0,0:05:51.93,0:05:59.07,Default,,0,0,0,,然后我们执行最大池化步骤，实际上是通过下采样减少这些特征图的大小。
Dialogue: 0,0:05:59.06,0:06:06.76,Default,,0,0,0,,这有助于神经网络识别图像中特征的大致位置，而不是它们的确切位置。
Dialogue: 0,0:06:06.78,0:06:10.21,Default,,0,0,0,,这也为下一层节省了一些计算。
Dialogue: 0,0:06:10.20,0:06:12.55,Default,,0,0,0,,这些步骤组成了第一层。
Dialogue: 0,0:06:12.52,0:06:18.09,Default,,0,0,0,,我们重复这些步骤来构建第二层，这有助于网络识别更复杂的特征。
Dialogue: 0,0:06:18.18,0:06:22.30,Default,,0,0,0,,在这个网络中，我们在第三层再做一次这个过程。
Dialogue: 0,0:06:22.34,0:06:31.62,Default,,0,0,0,,注意，最终的卷积层有64个节点，而不是32个，所以我们最终得到了64个二维特征图。
Dialogue: 0,0:06:31.69,0:06:40.41,Default,,0,0,0,,这些特征图将比原始图像小得多，主要是由于最大池化步骤大大减少了每层张量的大小。
Dialogue: 0,0:06:40.61,0:06:48.61,Default,,0,0,0,,卷积层结束时的最终特征图理想情况下将是一个复杂特征的集合，有助于我们定义图像。
Dialogue: 0,0:06:48.60,0:06:54.31,Default,,0,0,0,,例如，如果我们想识别狗的品种，这可能是尖耳朵与垂耳朵。
Dialogue: 0,0:06:54.52,0:07:04.56,Default,,0,0,0,,我们的分类器网络期望一个一维张量或向量输入，所以我们需要将我们的二维张量集合展开成一个长字符串的数字。
Dialogue: 0,0:07:04.59,0:07:08.89,Default,,0,0,0,,在这个例子中，这个向量被输入到一个相当浅的神经网络中。
Dialogue: 0,0:07:08.89,0:07:14.72,Default,,0,0,0,,第一层有64个全连接节点，仍然使用ReLU激活。
Dialogue: 0,0:07:14.67,0:07:18.09,Default,,0,0,0,,这些节点连接到一个只有一个节点的最终层。
Dialogue: 0,0:07:18.13,0:07:23.85,Default,,0,0,0,,该节点的激活函数是sigmoid函数，这在这种二分类器中很常见。
Dialogue: 0,0:07:23.88,0:07:31.48,Default,,0,0,0,,这个最终节点的输出是对输入的MFCC图像是否为词“停”或其他词的预测。
Dialogue: 0,0:07:31.53,0:07:35.29,Default,,0,0,0,,你会注意到在两层之间添加了一个dropout层。
Dialogue: 0,0:07:35.28,0:07:39.79,Default,,0,0,0,,dropout层在训练期间随机删除下一层的输入。
Dialogue: 0,0:07:39.81,0:07:43.42,Default,,0,0,0,,这是防止神经网络过拟合的简单方法。
Dialogue: 0,0:07:43.41,0:07:49.21,Default,,0,0,0,,注意，dropout层在测试和部署期间应禁用，Keras默认这样做。
Dialogue: 0,0:07:49.31,0:07:56.19,Default,,0,0,0,,现在我们对卷积神经网络有了广泛的理解，让我们回到程序中实现它。
Dialogue: 0,0:07:56.24,0:08:05.62,Default,,0,0,0,,如果我们打印出X集合的维度，可以看到它是一个16x16数组的集合，第一维是样本的索引。
Dialogue: 0,0:08:05.69,0:08:10.15,Default,,0,0,0,,TensorFlow期望输入到卷积神经网络的是四维张量。
Dialogue: 0,0:08:10.27,0:08:14.62,Default,,0,0,0,,具体来说，它希望是样本数、高度、宽度和通道数。
Dialogue: 0,0:08:14.65,0:08:18.18,Default,,0,0,0,,由于卷积神经网络需要处理彩色图像，
Dialogue: 0,0:08:18.15,0:08:23.22,Default,,0,0,0,,你通常会看到每个样本由三组二维数组组成，
Dialogue: 0,0:08:23.16,0:08:25.93,Default,,0,0,0,,分别对应红色、绿色和蓝色通道。
Dialogue: 0,0:08:25.92,0:08:30.06,Default,,0,0,0,,但是，我们的MFCCs每个样本只有一个通道。
Dialogue: 0,0:08:30.03,0:08:33.18,Default,,0,0,0,,但我们仍然需要输入四维数据到卷积神经网络，
Dialogue: 0,0:08:33.14,0:08:38.87,Default,,0,0,0,,所以我们使用reshape函数添加一个不包含任何额外信息的维度。
Dialogue: 0,0:08:38.87,0:08:45.92,Default,,0,0,0,,如果我们打印出输入数据的形状，可以看到我们已经将额外的通道作为第四维度添加到这些张量中。
Dialogue: 0,0:08:45.96,0:08:51.64,Default,,0,0,0,,为了检查，我们可以看到测试集中的一个样本是一个16x16数组。
Dialogue: 0,0:08:51.68,0:08:57.74,Default,,0,0,0,,有第三个维度，但由于只有一个元素，它基本上仍然是一个二维数组。
Dialogue: 0,0:08:57.85,0:09:00.36,Default,,0,0,0,,现在，我们使用Keras构建模型。
Dialogue: 0,0:09:00.71,0:09:04.30,Default,,0,0,0,,这与我们在Geeks for Geeks教程中找到的模型相同。
Dialogue: 0,0:09:04.29,0:09:09.45,Default,,0,0,0,,我们有三个带有ReLU激活和最大池化操作的卷积层。
Dialogue: 0,0:09:09.46,0:09:15.06,Default,,0,0,0,,这些输出进入一个由两层全连接神经网络。
Dialogue: 0,0:09:15.08,0:09:25.83,Default,,0,0,0,,第一层有64个节点，第二层只有一个节点，它给我们一个预测，MFCCs属于说出的词“停”或其他词。
Dialogue: 0,0:09:25.98,0:09:29.90,Default,,0,0,0,,我们可以使用summary函数打印出模型的概述。
Dialogue: 0,0:09:29.87,0:09:35.74,Default,,0,0,0,,在尝试优化模型的执行速度时，查看参数总数是有用的。
Dialogue: 0,0:09:35.77,0:09:40.79,Default,,0,0,0,,这些是模型中可以训练的权重或其他参数的数量。
Dialogue: 0,0:09:40.81,0:09:48.92,Default,,0,0,0,,这个数字给我们一个需要多少数学运算来训练和使用模型进行预测的概念。
Dialogue: 0,0:09:49.00,0:09:58.99,Default,,0,0,0,,理想情况下，你希望通过调整模型的形状和大小将这个数字尽可能低，同时仍然能够在交叉验证集上做出良好的预测。
Dialogue: 0,0:09:59.01,0:10:02.38,Default,,0,0,0,,接下来，我们设置模型训练并给它一些参数。
Dialogue: 0,0:10:02.39,0:10:10.05,Default,,0,0,0,,这些值以及其他一些值，例如MFCCs的大小和形状，组成了超参数集。
Dialogue: 0,0:10:10.05,0:10:14.38,Default,,0,0,0,,这些值在模型训练期间不会自动更新，
Dialogue: 0,0:10:14.33,0:10:18.60,Default,,0,0,0,,但你可以手动调整它们以影响模型的表现。
Dialogue: 0,0:10:18.71,0:10:26.21,Default,,0,0,0,,我们需要提供一个损失函数，这是模型在训练期间计算预测值与实际值之间距离的方法。
Dialogue: 0,0:10:26.23,0:10:31.59,Default,,0,0,0,,因为这是一个二分类问题，最终节点使用的是sigmoid激活，
Dialogue: 0,0:10:31.55,0:10:35.43,Default,,0,0,0,,所以我们希望使用二元交叉熵作为损失函数。
Dialogue: 0,0:10:35.43,0:10:43.24,Default,,0,0,0,,对于优化器，你会经常看到随机梯度下降、RMSProp和Adam在这种神经网络中使用。
Dialogue: 0,0:10:43.30,0:10:47.05,Default,,0,0,0,,我们找到的示例使用了RMSProp，所以我们也使用它。
Dialogue: 0,0:10:47.05,0:10:50.97,Default,,0,0,0,,请随意尝试不同的优化器函数，看看它如何影响训练。
Dialogue: 0,0:10:50.99,0:10:55.74,Default,,0,0,0,,最后，在训练期间记录一些指标以便稍后绘图是有帮助的。
Dialogue: 0,0:10:55.73,0:10:59.56,Default,,0,0,0,,所以我们让它记录准确率，缩写为ACC。
Dialogue: 0,0:10:59.65,0:11:02.59,Default,,0,0,0,,现在我们有了模型设置，就可以训练它了。
Dialogue: 0,0:11:02.68,0:11:10.78,Default,,0,0,0,,我们通过调用fit函数来实现这一点，并传递我们的训练样本和y向量中的相应真实答案。
Dialogue: 0,0:11:10.78,0:11:14.78,Default,,0,0,0,,我们告诉它我们希望经历多少个epoch并给它一个batch size。
Dialogue: 0,0:11:14.75,0:11:20.43,Default,,0,0,0,,随意调整这些数字，看看是否可以加快训练速度或提高准确性。
Dialogue: 0,0:11:20.68,0:11:24.26,Default,,0,0,0,,最后，我们提供验证样本和答案。
Dialogue: 0,0:11:24.32,0:11:31.02,Default,,0,0,0,,我们希望看到模型在预测未见数据时的表现作为准确度的一个部分。
Dialogue: 0,0:11:31.04,0:11:33.49,Default,,0,0,0,,让我们运行这个。可能需要几分钟。
Dialogue: 0,0:11:33.50,0:11:36.88,Default,,0,0,0,,完成后，查看最终epoch的输出。
Dialogue: 0,0:11:36.90,0:11:41.81,Default,,0,0,0,,你应该看到一个准确率分数，它告诉你模型在训练数据上的表现，
Dialogue: 0,0:11:41.79,0:11:47.59,Default,,0,0,0,,以及一个验证准确率分数，它告诉你模型在交叉验证数据上的表现。
Dialogue: 0,0:11:47.58,0:11:51.04,Default,,0,0,0,,让我们绘制准确率和损失随epoch变化的曲线。
Dialogue: 0,0:11:51.07,0:11:54.27,Default,,0,0,0,,我们将导入Matplotlib并创建两个图。
Dialogue: 0,0:11:54.32,0:12:00.16,Default,,0,0,0,,训练准确率用点表示，交叉验证准确率用实线表示。
Dialogue: 0,0:12:00.17,0:12:06.10,Default,,0,0,0,,训练和验证损失和准确率曲线应都在各自值附近收敛。
Dialogue: 0,0:12:06.20,0:12:12.11,Default,,0,0,0,,如果你看到曲线在几个epoch之后仍在大幅波动，说明训练过程中出了问题。
Dialogue: 0,0:12:12.16,0:12:20.14,Default,,0,0,0,,如你所见，我们的模型表现非常好，准确率在90%以上，比只是每次都猜“不是停”要好一点。
Dialogue: 0,0:12:20.18,0:12:27.52,Default,,0,0,0,,大多数情况下，你会发现模型在训练数据上的表现比在验证数据上更好，经过若干个epoch后更是如此。
Dialogue: 0,0:12:27.66,0:12:35.52,Default,,0,0,0,,这是因为模型开始学习训练集中样本的独特特征，这些特征无法很好地推广到未见数据上。
Dialogue: 0,0:12:35.53,0:12:40.06,Default,,0,0,0,,这被称为过拟合，当你部署模型时可能会造成问题。
Dialogue: 0,0:12:40.10,0:12:50.04,Default,,0,0,0,,寻找训练准确率和验证准确率之间的大差距，以及损失函数上的差距，以确定你的模型是否过拟合了训练样本。
Dialogue: 0,0:12:50.08,0:13:00.82,Default,,0,0,0,,你可能需要提取不同的特征，使用不同的模型结构，或尝试不同的训练参数，以找到一个不过拟合且能够很好地推广到未见数据上的模型。
Dialogue: 0,0:13:00.84,0:13:05.67,Default,,0,0,0,,请注意，即使使用相同的参数和超参数再次运行训练步骤，
Dialogue: 0,0:13:05.84,0:13:12.03,Default,,0,0,0,,也可能产生不同的结果，因为神经网络中的权重在训练前是随机初始化的。
Dialogue: 0,0:13:12.07,0:13:15.27,Default,,0,0,0,,我认为这个模型对于一个原型来说已经足够好了。
Dialogue: 0,0:13:15.27,0:13:21.43,Default,,0,0,0,,不过，如果你记得上集节目，我们只使用了10%的数据进行训练和验证。
Dialogue: 0,0:13:21.44,0:13:28.97,Default,,0,0,0,,如果你想调整一些模型参数和超参数（例如MFCC计算），这个子集可能会有用，但
Dialogue: 0,0:13:28.92,0:13:38.00,Default,,0,0,0,,既然我们准备好测试并希望部署我们的模型，我们就需要回去对所有数据运行特征提取和训练脚本。
Dialogue: 0,0:13:37.99,0:13:46.45,Default,,0,0,0,,回到上集节目中编写的特征提取脚本，将保持样本百分比从10%更改为100%。
Dialogue: 0,0:13:46.52,0:13:48.62,Default,,0,0,0,,现在重新运行脚本。
Dialogue: 0,0:13:48.61,0:13:54.76,Default,,0,0,0,,注意，特征提取将花费更长时间，可能需要一个小时或更久，具体取决于你的计算机。
Dialogue: 0,0:13:54.74,0:13:59.70,Default,,0,0,0,,完成后，我们应该在NPZ文件中有完整的特征集。
Dialogue: 0,0:13:59.73,0:14:03.29,Default,,0,0,0,,因此，返回分类器训练脚本并再次运行它。
Dialogue: 0,0:14:03.25,0:14:08.68,Default,,0,0,0,,像特征提取一样，训练将花费更长时间，可能需要一个小时左右。
Dialogue: 0,0:14:08.79,0:14:14.57,Default,,0,0,0,,因为这次我们使用了所有数据，所以理论上应该产生一个更强大的模型。
Dialogue: 0,0:14:14.55,0:14:20.10,Default,,0,0,0,,完成后，再次绘制准确率和损失曲线，确保它们看起来合理。
Dialogue: 0,0:14:20.21,0:14:25.29,Default,,0,0,0,,验证准确率是否高于随机猜测“不是停”的机会？
Dialogue: 0,0:14:25.38,0:14:29.58,Default,,0,0,0,,我们的训练是否没有过度拟合模型？
Dialogue: 0,0:14:29.69,0:14:36.20,Default,,0,0,0,,我们最后需要做的是将模型保存为一个文件，我们可以使用save model函数来完成。
Dialogue: 0,0:14:36.21,0:14:40.65,Default,,0,0,0,,注意，我们将保存为wakeword stop model dot h5。
Dialogue: 0,0:14:40.62,0:14:45.98,Default,,0,0,0,,如果我们想在新数据上进行预测，可以在TensorFlow中加载这个模型。
Dialogue: 0,0:14:46.07,0:14:51.26,Default,,0,0,0,,现在我们的模型完成了，我们可以使用预留的测试数据进行测试。
Dialogue: 0,0:14:51.30,0:14:56.46,Default,,0,0,0,,首先，让我们打印出所有指向“停”这个词的训练数据索引。
Dialogue: 0,0:14:56.42,0:15:02.50,Default,,0,0,0,,我们从文件中加载模型并让它预测这些索引附近的10个训练样本的输出。
Dialogue: 0,0:15:02.56,0:15:15.50,Default,,0,0,0,,由于我们使用的是sigmoid函数作为最终激活，输出实际上是模型认为输入属于“停”类别而不是“不是停”类别的置信度评分。
Dialogue: 0,0:15:15.73,0:15:21.83,Default,,0,0,0,,通常，我们会认为任何超过0.5的分数都是我们的目标唤醒词或“停”。
Dialogue: 0,0:15:21.81,0:15:29.97,Default,,0,0,0,,如你所见，对于对应“停”这个词的样本，模型应该会产生高于0.5的置信度评分。
Dialogue: 0,0:15:29.96,0:15:31.61,Default,,0,0,0,,然而，这并不完美。
Dialogue: 0,0:15:31.60,0:15:36.85,Default,,0,0,0,,你可以很容易地找到不会产生高于0.5预测分数的测试样本。
Dialogue: 0,0:15:36.80,0:15:44.50,Default,,0,0,0,,同样地，你也可以在“不是停”类别中找到预测分数高于0.5的例子。
Dialogue: 0,0:15:44.50,0:15:48.50,Default,,0,0,0,,话虽如此，对于一个原型模型，它似乎工作得足够好了。
Dialogue: 0,0:15:48.67,0:15:59.91,Default,,0,0,0,,最后，我们可以调用evaluate函数，使用所有测试数据，这将给我们一个损失评分和我们要求模型记录的任何指标，在这种情况下是准确率。
Dialogue: 0,0:15:59.91,0:16:03.90,Default,,0,0,0,,理想情况下，这应该给你一个接近验证准确率的结果。
Dialogue: 0,0:16:03.91,0:16:12.92,Default,,0,0,0,,看来我们的模型在预测一个一秒的音频片段中是否包含“停”这个词时准确率约为98.4%。
Dialogue: 0,0:16:12.89,0:16:16.85,Default,,0,0,0,,如果测试准确率远低于验证准确率，
Dialogue: 0,0:16:16.82,0:16:23.15,Default,,0,0,0,,这意味着模型已过拟合到验证数据，你可能需要重新开始。
Dialogue: 0,0:16:23.32,0:16:30.69,Default,,0,0,0,,这是在白皮书或项目报告中被问及模型在未见数据上的表现时你会提供的数字。
Dialogue: 0,0:16:30.71,0:16:33.91,Default,,0,0,0,,再次强调，我对这个模型的表现非常满意。
Dialogue: 0,0:16:33.85,0:16:37.13,Default,,0,0,0,,希望这能帮助你开始训练自己的神经网络。
Dialogue: 0,0:16:37.12,0:16:43.35,Default,,0,0,0,,我知道这需要很多时间，但请随意尝试这个示例中的一些参数和设置。
Dialogue: 0,0:16:43.34,0:16:51.64,Default,,0,0,0,,在下集节目中，我们将把我们的保存模型文件转换为TensorFlow Lite模型文件，然后将其部署在Raspberry Pi上。
Dialogue: 0,0:16:51.63,0:16:55.62,Default,,0,0,0,,这是创建你自己的边缘AI设备的开始
Dialogue: 0,0:16:55.75,0:16:57.03,Default,,0,0,0,,再见。
