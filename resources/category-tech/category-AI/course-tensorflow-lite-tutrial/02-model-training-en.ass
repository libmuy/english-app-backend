[Script Info]
; Script generated by Aegisub 9706-cibuilds-20caaabc0
; http://www.aegisub.org/
Title: Default Aegisub file
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: None

[Aegisub Project Garbage]
Export Encoding: Unicode (UTF-8)
Audio File: part2.wav
Video Zoom Percent: 1.000000
Active Line: 6

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,48,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:11.02,Default,,0,0,0,,On the last episode, we used Python to compute the Mell frequency sepstral coefficients, or MFCCs, of the audio files found in the Google Speech Commands data set.
Dialogue: 0,0:00:10.97,0:00:16.91,Default,,0,0,0,,We also divided these features and labels up into training, validation, and test sets.
Dialogue: 0,0:00:16.91,0:00:19.39,Default,,0,0,0,,Now we're ready to train our neural network.
Dialogue: 0,0:00:19.60,0:00:26.13,Default,,0,0,0,,When we think of training a model on command words, we might think of having the model recognize one of many different words.
Dialogue: 0,0:00:26.11,0:00:34.45,Default,,0,0,0,,So if we said stop, our algorithm would compute the MFCCs of that word and send those coefficients as features to our model.
Dialogue: 0,0:00:34.45,0:00:42.92,Default,,0,0,0,,The model would then make a prediction based on those features and tell us that it thinks we said stop out of all the possible wake words it knows.
Dialogue: 0,0:00:43.06,0:00:47.68,Default,,0,0,0,,While this might be useful in some scenarios, such as giving commands to a robot, 
Dialogue: 0,0:00:47.62,0:00:52.99,Default,,0,0,0,,it's very computationally expensive to compute the probabilities of all the different words.
Dialogue: 0,0:00:53.03,0:01:03.64,Default,,0,0,0,,Since we only care about one word, it's much easier to train a binary classifier to recognize that one word and bundle every other sound and word into a single category.
Dialogue: 0,0:01:03.68,0:01:07.42,Default,,0,0,0,,Our two categories will be stop and not stop.
Dialogue: 0,0:01:07.38,0:01:15.59,Default,,0,0,0,,Making a prediction with the model will then give us the probability that it thinks it recognized the word stop from the MFCC features we give it.
Dialogue: 0,0:01:15.76,0:01:22.48,Default,,0,0,0,,If that probability is over some threshold, we'll have our program respond appropriately by, say, turning on a light.
Dialogue: 0,0:01:22.57,0:01:30.58,Default,,0,0,0,,So that means we need to train a mathematical model that classifies sounds as either the spoken word stop or something else.
Dialogue: 0,0:01:30.64,0:01:33.35,Default,,0,0,0,,In a new notebook, let's load our modules.
Dialogue: 0,0:01:33.59,0:01:36.11,Default,,0,0,0,,We'll need OS to deal with loading files.
Dialogue: 0,0:01:36.10,0:01:40.36,Default,,0,0,0,,We'll also want layers and models from Keras to build our neural network.
Dialogue: 0,0:01:40.48,0:01:44.55,Default,,0,0,0,,Finally, we need NumPy to help us deal with matrices and other tensors.
Dialogue: 0,0:01:44.60,0:01:50.72,Default,,0,0,0,,As a quick test, let's read the words that are available to us from the data set, leaving off the background noise.
Dialogue: 0,0:01:50.68,0:01:55.36,Default,,0,0,0,,Next, we'll set the path to our feature set file that we created in the last episode.
Dialogue: 0,0:01:55.43,0:02:00.56,Default,,0,0,0,,Additionally, we'll want to save our neural network model to a file when we're done, so
Dialogue: 0,0:02:00.52,0:02:02.25,Default,,0,0,0,,we'll set the file name here.
Dialogue: 0,0:02:02.26,0:02:04.94,Default,,0,0,0,,We'll also define our wake word here.
Dialogue: 0,0:02:04.92,0:02:09.60,Default,,0,0,0,,Note that it must be one of the ones listed from the available targets in the data set.
Dialogue: 0,0:02:09.77,0:02:14.70,Default,,0,0,0,,We can then use NumPy to load the feature set file and print out the sets available to us.
Dialogue: 0,0:02:14.75,0:02:18.09,Default,,0,0,0,,Let's assign those to some variables for easier access.
Dialogue: 0,0:02:18.21,0:02:22.57,Default,,0,0,0,,A tensor is a collection of data arranged in any number of dimensions.
Dialogue: 0,0:02:22.57,0:02:25.70,Default,,0,0,0,,A matrix is simply a two-dimensional tensor.
Dialogue: 0,0:02:25.69,0:02:30.77,Default,,0,0,0,,A grayscale image, like the ones we were creating with the MFCCs, is just a matrix.
Dialogue: 0,0:02:30.85,0:02:37.29,Default,,0,0,0,,So if we have a collection of matrices ordered in a linear fashion, we've created a three-dimensional tensor.
Dialogue: 0,0:02:37.28,0:02:43.75,Default,,0,0,0,,If we look at the dimensions of the feature sets, we can see that the first dimension is the number of samples in that set.
Dialogue: 0,0:02:43.73,0:02:49.59,Default,,0,0,0,,And the other two dimensions are the number of coefficients and the number of sets of coefficients in each sample.
Dialogue: 0,0:02:49.66,0:02:56.26,Default,,0,0,0,,If we look at one of the sets of labels, we can see that it's a collection of numbers that correspond to the different words.
Dialogue: 0,0:02:56.38,0:03:00.43,Default,,0,0,0,,Zero is backward, one is bed, two is bird, and so on.
Dialogue: 0,0:03:00.53,0:03:03.19,Default,,0,0,0,,We don't want that for a binary classifier.
Dialogue: 0,0:03:03.18,0:03:11.03,Default,,0,0,0,,So we find the index of our target word, stop, and use NumPy's equal function to only keep the stop label.
Dialogue: 0,0:03:11.09,0:03:18.47,Default,,0,0,0,,Normally, this function returns true and false, so we'll want to translate them to one and zero using the asType function.
Dialogue: 0,0:03:18.49,0:03:24.51,Default,,0,0,0,,I'll keep them as 64-bit floating point values, since that seems to be what they were originally stored as.
Dialogue: 0,0:03:24.51,0:03:30.54,Default,,0,0,0,,If we look again, we see that the stop labels now have a one and everything else has a zero.
Dialogue: 0,0:03:30.62,0:03:31.82,Default,,0,0,0,,Here's the tricky part.
Dialogue: 0,0:03:31.80,0:03:34.25,Default,,0,0,0,,There aren't as many ones in this set.
Dialogue: 0,0:03:34.26,0:03:40.10,Default,,0,0,0,,In fact, we can see that only about 4% of labels in the validation set are one.
Dialogue: 0,0:03:40.04,0:03:45.12,Default,,0,0,0,,That means if the model were to just give us the answer of not stop for everything,
Dialogue: 0,0:03:45.13,0:03:48.27,Default,,0,0,0,,it would be correct over 95% of the time.
Dialogue: 0,0:03:48.26,0:03:53.04,Default,,0,0,0,,So we need to do better than that if we hope to identify when someone says stop.
Dialogue: 0,0:03:53.05,0:04:02.62,Default,,0,0,0,,A convolutional neural network, which you'll often see abbreviated as ConvNet or CNN, seems to be one of the most popular methods for classifying images.
Dialogue: 0,0:04:02.57,0:04:11.15,Default,,0,0,0,,I'll be honest in that I don't fully understand the details of how a ConvNet works, but there lots of good resources out there if you want to learn more about them.
Dialogue: 0,0:04:11.15,0:04:13.20,Default,,0,0,0,,For now, we just need to get something working.
Dialogue: 0,0:04:13.32,0:04:21.51,Default,,0,0,0,,I found a simple image classification network on this Geeks for Geeks tutorial that seems to give us okay accuracy, and it's easy to implement.
Dialogue: 0,0:04:21.70,0:04:23.98,Default,,0,0,0,,We'll start with that for our classifier.
Dialogue: 0,0:04:24.00,0:04:26.89,Default,,0,0,0,,You are welcome to experiment with other networks too.
Dialogue: 0,0:04:26.93,0:04:31.67,Default,,0,0,0,,Tweaking some of the weights in the VGG16 network seems to be pretty popular.
Dialogue: 0,0:04:31.66,0:04:40.41,Default,,0,0,0,,Let's take a look at the network from that tutorial to get a basic idea of what's going A convolutional neural network usually consists of two different parts.
Dialogue: 0,0:04:40.44,0:04:43.22,Default,,0,0,0,,The first is the set of convolutional layers.
Dialogue: 0,0:04:43.19,0:04:47.77,Default,,0,0,0,,These layers act to automatically learn and extract features from the image.
Dialogue: 0,0:04:47.85,0:04:55.00,Default,,0,0,0,,These features are then passed to a fully connected neural network that attempts to classify the image based on the features provided.
Dialogue: 0,0:04:54.99,0:04:59.23,Default,,0,0,0,,The first section of the convolutional set consists of three steps.
Dialogue: 0,0:04:59.37,0:05:02.51,Default,,0,0,0,,The first step is the actual convolution operation.
Dialogue: 0,0:05:02.50,0:05:10.28,Default,,0,0,0,,It consists of moving a window across the whole image as a sort of filter in order to extract some features, such as detecting edges.
Dialogue: 0,0:05:10.38,0:05:18.53,Default,,0,0,0,,This sliding window filter is known as a kernel and performs some math operations as it samples a set of pixels from the image.
Dialogue: 0,0:05:18.62,0:05:21.96,Default,,0,0,0,,In this example, the window is 2x2 pixels.
Dialogue: 0,0:05:22.02,0:05:27.91,Default,,0,0,0,,The weights used in this kernel are different for every node and are updated automatically during training.
Dialogue: 0,0:05:27.94,0:05:32.32,Default,,0,0,0,,With this example, we have 32 nodes in the first convolutional layer.
Dialogue: 0,0:05:32.31,0:05:40.26,Default,,0,0,0,,So we end up with 32 different filtered images that give us some fine details in the image, such as edges and corners.
Dialogue: 0,0:05:40.29,0:05:46.96,Default,,0,0,0,,The rectified linear unit, or ReLU activation, simply sets all negative numbers in the feature maps to zero.
Dialogue: 0,0:05:46.92,0:05:51.96,Default,,0,0,0,,It adds a level of non-linearity to the nodes, which allows us to train the model.
Dialogue: 0,0:05:51.93,0:05:59.07,Default,,0,0,0,,We then perform a max pooling step, which in effect reduces the size of these feature maps by downsampling them.
Dialogue: 0,0:05:59.06,0:06:06.76,Default,,0,0,0,,This helps the neural network identify where features are supposed to approximately be in the image instead of their exact locations.
Dialogue: 0,0:06:06.78,0:06:10.21,Default,,0,0,0,,It also saves us some computations in the next layer.
Dialogue: 0,0:06:10.20,0:06:12.55,Default,,0,0,0,,These steps make up the first layer.
Dialogue: 0,0:06:12.52,0:06:18.09,Default,,0,0,0,,We repeat these steps for the second layer, which helps the network identify more complex features.
Dialogue: 0,0:06:18.18,0:06:22.30,Default,,0,0,0,,In this network, we do this process one more time in the third layer.
Dialogue: 0,0:06:22.34,0:06:31.62,Default,,0,0,0,,Notice that the final convolutional layer has 64 nodes instead of 32, so we end up with 64 two-dimensional maps of features.
Dialogue: 0,0:06:31.69,0:06:40.41,Default,,0,0,0,,These maps will be much smaller than the original image, mostly due to the max pooling steps that drastically reduce the size of the tensors in each layer.
Dialogue: 0,0:06:40.61,0:06:48.61,Default,,0,0,0,,The final feature maps at the end of the convolutional layers will, ideally, be a collection of complex features that help us define the image.
Dialogue: 0,0:06:48.60,0:06:54.31,Default,,0,0,0,,For example, if we wanted to identify breeds of dogs, this might be pointed ears versus floppy ears.
Dialogue: 0,0:06:54.52,0:07:04.56,Default,,0,0,0,,Our classifier network expects a one-dimensional tensor, or vector input, so we need to flatten our collection of two-dimensional tensors into one long string of numbers.
Dialogue: 0,0:07:04.59,0:07:08.89,Default,,0,0,0,,This vector is then fed into a rather shallow neural network in this example.
Dialogue: 0,0:07:08.89,0:07:14.72,Default,,0,0,0,,The first layer is 64 fully connected nodes with the ReLU activation being used again.
Dialogue: 0,0:07:14.67,0:07:18.09,Default,,0,0,0,,These nodes feed a final layer that is just one node.
Dialogue: 0,0:07:18.13,0:07:23.85,Default,,0,0,0,,That node's activation is the sigmoid function, which is common in binary classifiers like this one.
Dialogue: 0,0:07:23.88,0:07:31.48,Default,,0,0,0,,The output of this final node is a prediction of whether the input MFCC image was the word stop, or something else.
Dialogue: 0,0:07:31.53,0:07:35.29,Default,,0,0,0,,You'll notice that there is a dropout layer added between the two layers.
Dialogue: 0,0:07:35.28,0:07:39.79,Default,,0,0,0,,A dropout layer randomly removes inputs to the next layer during training.
Dialogue: 0,0:07:39.81,0:07:43.42,Default,,0,0,0,,It is an easy way to help prevent overfitting of the neural network.
Dialogue: 0,0:07:43.41,0:07:49.21,Default,,0,0,0,,Note that the dropout layer should be disabled during testing and deployment, which Keras does by default.
Dialogue: 0,0:07:49.31,0:07:56.19,Default,,0,0,0,,Now that we have a broad understanding of what's going on in this ConvNet, let's head back to our program to implement it.
Dialogue: 0,0:07:56.24,0:08:05.62,Default,,0,0,0,,If we print out the dimensions of our XSETs, we can see that it's a collection of 16 by 16 arrays, with the first dimension being the index of the sample.
Dialogue: 0,0:08:05.69,0:08:10.15,Default,,0,0,0,,TensorFlow expects tensors in four dimensions as inputs to ConvNets.
Dialogue: 0,0:08:10.27,0:08:14.62,Default,,0,0,0,,Specifically, it wants sample number, height, width, and channel.
Dialogue: 0,0:08:14.65,0:08:18.18,Default,,0,0,0,,Since ConvNets need to be able to handle color images, 
Dialogue: 0,0:08:18.15,0:08:23.22,Default,,0,0,0,,you'll often see each sample composed of three sets of two-dimensional arrays, 
Dialogue: 0,0:08:23.16,0:08:25.93,Default,,0,0,0,,one for each red, green, and blue channel.
Dialogue: 0,0:08:25.92,0:08:30.06,Default,,0,0,0,,However, our MFCCs only have one channel per sample.
Dialogue: 0,0:08:30.03,0:08:33.18,Default,,0,0,0,,But we still need to feed the ConvNet four dimensions,
Dialogue: 0,0:08:33.14,0:08:38.87,Default,,0,0,0,,so we use the reshape function to add an extra dimension that doesn't hold any extra information.
Dialogue: 0,0:08:38.87,0:08:45.92,Default,,0,0,0,,If we print out the shape of our input data, we can see that we have added the extra channel as the fourth dimension on these tensors.
Dialogue: 0,0:08:45.96,0:08:51.64,Default,,0,0,0,,Just to check, we can see that one sample from our test set is a 16 by 16 array.
Dialogue: 0,0:08:51.68,0:08:57.74,Default,,0,0,0,,There's a third dimension, but since there's only one element, it's still basically a two-dimensional array.
Dialogue: 0,0:08:57.85,0:09:00.36,Default,,0,0,0,,Now, we build the model using Keras.
Dialogue: 0,0:09:00.71,0:09:04.30,Default,,0,0,0,,This is the same model we found on that Geeks for Geeks tutorial.
Dialogue: 0,0:09:04.29,0:09:09.45,Default,,0,0,0,,We have three convolutional layers with ReLU activations and max pooling operations.
Dialogue: 0,0:09:09.46,0:09:15.06,Default,,0,0,0,,The output of that gets fed into a fully connected, or dense, neural network with two layers.
Dialogue: 0,0:09:15.08,0:09:25.83,Default,,0,0,0,,The first has 64 nodes and the second has only one node that gives us a prediction of whether the provided MFCCs belong to the spoken word stop or something else.
Dialogue: 0,0:09:25.98,0:09:29.90,Default,,0,0,0,,We can use the summary function to print out an overview of the model.
Dialogue: 0,0:09:29.87,0:09:35.74,Default,,0,0,0,,When trying to optimize a model for execution speed, it can be useful to look at the total number of parameters.
Dialogue: 0,0:09:35.77,0:09:40.79,Default,,0,0,0,,These are the number of weights or other parameters that can be trained in the model.
Dialogue: 0,0:09:40.81,0:09:48.92,Default,,0,0,0,,And this number gives us an idea of how many math operations are needed to both train the model as well as use it for predictions.
Dialogue: 0,0:09:49.00,0:09:58.99,Default,,0,0,0,,Ideally, you want to get this number to be as low as possible by playing with the model's shape and size while still having the model make good predictions on the cross-validation set.
Dialogue: 0,0:09:59.01,0:10:02.38,Default,,0,0,0,,Next, we set up the model for training and give it some parameters.
Dialogue: 0,0:10:02.39,0:10:10.05,Default,,0,0,0,,These values, along with some others, such as the size and shape of the MFCCs, make up a set known as the hyperparameters.
Dialogue: 0,0:10:10.05,0:10:14.38,Default,,0,0,0,,These values do not get automatically updated during the training of the model, 
Dialogue: 0,0:10:14.33,0:10:18.60,Default,,0,0,0,,but you can adjust them manually to affect how the model performs.
Dialogue: 0,0:10:18.71,0:10:26.21,Default,,0,0,0,,We need to provide a loss function, which is how the model calculates how far away the prediction is from the actual value during training.
Dialogue: 0,0:10:26.23,0:10:31.59,Default,,0,0,0,,Because this is a binary classification problem with a sigmoid activation on the final node,
Dialogue: 0,0:10:31.55,0:10:35.43,Default,,0,0,0,,we want to use binary cross entropy as our loss function.
Dialogue: 0,0:10:35.43,0:10:43.24,Default,,0,0,0,,For optimizers, you'll see stochastic gradient descent, RMSProp, and Adam used very frequently with neural networks like this.
Dialogue: 0,0:10:43.30,0:10:47.05,Default,,0,0,0,,The example we found uses RMSProp, so we'll go with that.
Dialogue: 0,0:10:47.05,0:10:50.97,Default,,0,0,0,,Feel free to try different optimizer functions to see how it affects training.
Dialogue: 0,0:10:50.99,0:10:55.74,Default,,0,0,0,,Finally, it can be helpful to record some metrics during training that we can plot later.
Dialogue: 0,0:10:55.73,0:10:59.56,Default,,0,0,0,,So we'll have it record accuracy, abbreviated ACC.
Dialogue: 0,0:10:59.65,0:11:02.59,Default,,0,0,0,,Now that we have the model set up, it's time to train it.
Dialogue: 0,0:11:02.68,0:11:10.78,Default,,0,0,0,,We do that by calling the fit function, and we pass it our training samples along with the associated ground truth answers in the y vector.
Dialogue: 0,0:11:10.78,0:11:14.78,Default,,0,0,0,,We tell it how many epochs we want to go through and give it a batch size.
Dialogue: 0,0:11:14.75,0:11:20.43,Default,,0,0,0,,Feel free to play around with both of these numbers to see if you can make it train faster or more accurately.
Dialogue: 0,0:11:20.68,0:11:24.26,Default,,0,0,0,,Finally, we provide it the validation samples and answers.
Dialogue: 0,0:11:24.32,0:11:31.02,Default,,0,0,0,,We will want to look at how well the model performs on predicting unseen data as part of our accuracy measurement.
Dialogue: 0,0:11:31.04,0:11:33.49,Default,,0,0,0,,Let's run this. It might take a few minutes.
Dialogue: 0,0:11:33.50,0:11:36.88,Default,,0,0,0,,When it's done, take a look at the output of the final epoch.
Dialogue: 0,0:11:36.90,0:11:41.81,Default,,0,0,0,,You should see an accuracy score, which tells you how well the model performed on training data 
Dialogue: 0,0:11:41.79,0:11:47.59,Default,,0,0,0,,and a validation accuracy score, which tells you how well the model performed on the cross validation data.
Dialogue: 0,0:11:47.58,0:11:51.04,Default,,0,0,0,,Let's plot the accuracy and loss as functions of epochs.
Dialogue: 0,0:11:51.07,0:11:54.27,Default,,0,0,0,,We'll import Matplotlib and create two plots.
Dialogue: 0,0:11:54.32,0:12:00.16,Default,,0,0,0,,The training accuracy is given by dots and the cross validation accuracy is given by the solid line.
Dialogue: 0,0:12:00.17,0:12:06.10,Default,,0,0,0,,The training and validation loss and accuracy curves should all converge around separate values.
Dialogue: 0,0:12:06.20,0:12:12.11,Default,,0,0,0,,If you see the curves still wildly swinging after a few epochs, it means something went wrong during training.
Dialogue: 0,0:12:12.16,0:12:20.14,Default,,0,0,0,,As you can see, our model did very well in the upper 90s, a little better than just guessing that the answer is not stop every time.
Dialogue: 0,0:12:20.18,0:12:27.52,Default,,0,0,0,,Most of the time, you will find that the model performs better on the training data than on the validation data after a number of epochs.
Dialogue: 0,0:12:27.66,0:12:35.52,Default,,0,0,0,,This is because the model starts to learn features unique to the samples in the training set that do not generalize well to unseen data.
Dialogue: 0,0:12:35.53,0:12:40.06,Default,,0,0,0,,This is known as overfitting and can cause problems when you deploy your model.
Dialogue: 0,0:12:40.10,0:12:50.04,Default,,0,0,0,,Look for a large gap between training accuracy and validation accuracy, as well as a gap in the loss function to see if your model has been overfit to the training samples.
Dialogue: 0,0:12:50.08,0:13:00.82,Default,,0,0,0,,You might have to extract different features, use different model structures, or try different training parameters to find a model that does not overfit and generalizes well to unseen data.
Dialogue: 0,0:13:00.84,0:13:05.67,Default,,0,0,0,,Note that running the training step again, even with the same parameters and hyperparameters,
Dialogue: 0,0:13:05.84,0:13:12.03,Default,,0,0,0,,can produce different results, as the weights in the neural network are randomly initialized before training.
Dialogue: 0,0:13:12.07,0:13:15.27,Default,,0,0,0,,I think this model will work well enough for a first prototype.
Dialogue: 0,0:13:15.27,0:13:21.43,Default,,0,0,0,,However, if you remember from the previous episode, we are only using 10% of the data for training and validation.
Dialogue: 0,0:13:21.44,0:13:28.97,Default,,0,0,0,,This can be a useful subset if you want to tweak some of the model parameters and hyperparameters, like the MFCC calculations. but
Dialogue: 0,0:13:28.92,0:13:38.00,Default,,0,0,0,,since we're ready to test and hopefully deploy our model, we'll want to go back and run both the feature extraction and training scripts on all of the data.
Dialogue: 0,0:13:37.99,0:13:46.45,Default,,0,0,0,,Go back to the feature extraction script that we wrote in the last episode and change the keep samples percentage from 10% to 100%.
Dialogue: 0,0:13:46.52,0:13:48.62,Default,,0,0,0,,Now just run the script again.
Dialogue: 0,0:13:48.61,0:13:54.76,Default,,0,0,0,,Note that feature extraction will take a much longer time, possibly an hour or two, depending on your computer.
Dialogue: 0,0:13:54.74,0:13:59.70,Default,,0,0,0,,When that's done, we should have the full set of features stored in the NPZ file.
Dialogue: 0,0:13:59.73,0:14:03.29,Default,,0,0,0,,So return to the classifier training script and run it again.
Dialogue: 0,0:14:03.25,0:14:08.68,Default,,0,0,0,,Like with the feature extraction, training will take much longer, up to maybe an hour or so.
Dialogue: 0,0:14:08.79,0:14:14.57,Default,,0,0,0,,Because we're using all of the data this time, it should, in theory, produce a more robust model.
Dialogue: 0,0:14:14.55,0:14:20.10,Default,,0,0,0,,When it's done plot the accuracy and loss curves again to make sure that they look reasonable.
Dialogue: 0,0:14:20.21,0:14:25.29,Default,,0,0,0,,Is the validation accuracy above the chance of just randomly guessing not stop?
Dialogue: 0,0:14:25.38,0:14:29.58,Default,,0,0,0,,And does it appear that our training did not overfit the model too much?
Dialogue: 0,0:14:29.69,0:14:36.20,Default,,0,0,0,,The last thing we need to do is save the model as a file, which we can do with the save model function.
Dialogue: 0,0:14:36.21,0:14:40.65,Default,,0,0,0,,Note that we'll be saving it as wakeword stop model dot h5.
Dialogue: 0,0:14:40.62,0:14:45.98,Default,,0,0,0,,And we can load this model in TensorFlow if we want to make predictions on new data.
Dialogue: 0,0:14:46.07,0:14:51.26,Default,,0,0,0,,Now that our model is done, we can test it using the test data that we set aside.
Dialogue: 0,0:14:51.30,0:14:56.46,Default,,0,0,0,,First, let's print out all of the indices for the training data that point to the word stop.
Dialogue: 0,0:14:56.42,0:15:02.50,Default,,0,0,0,,We load our model from the file and have it predict the output from 10 of the training samples around this index.
Dialogue: 0,0:15:02.56,0:15:15.50,Default,,0,0,0,,Because we are using the sigmoid function for the final activation, the output of the essentially a confidence score of how much the model thinks the input is in the class stop as opposed to not stop.
Dialogue: 0,0:15:15.73,0:15:21.83,Default,,0,0,0,,Generally, we would consider anything over point five as being our target wakeword or stop.
Dialogue: 0,0:15:21.81,0:15:29.97,Default,,0,0,0,,As you can see, the model should produce a confidence score that's above point five for samples that correspond to the word stop. 
Dialogue: 0,0:15:29.96,0:15:31.61,Default,,0,0,0,,However, it's not perfect.
Dialogue: 0,0:15:31.60,0:15:36.85,Default,,0,0,0,,You can easily find test samples that do not produce a predicted score above point five.
Dialogue: 0,0:15:36.80,0:15:44.50,Default,,0,0,0,,And similarly, you can find examples in the not stop category that do produce a predicted score above point five.
Dialogue: 0,0:15:44.50,0:15:48.50,Default,,0,0,0,,That being said, it seems to work well enough for a prototype model.
Dialogue: 0,0:15:48.67,0:15:59.91,Default,,0,0,0,,Finally, we can call the evaluate function using all of the test data, which will give us a loss score and any metrics that we ask the model to record, which is accuracy in this case.
Dialogue: 0,0:15:59.91,0:16:03.90,Default,,0,0,0,,Ideally, this should give you something close to your validation accuracy.
Dialogue: 0,0:16:03.91,0:16:12.92,Default,,0,0,0,,It seems that our model is about 98.4% accurate at predicting if a one second clip of audio contains the word stop.
Dialogue: 0,0:16:12.89,0:16:16.85,Default,,0,0,0,,If the test accuracy is much less than the validation accuracy,
Dialogue: 0,0:16:16.82,0:16:23.15,Default,,0,0,0,,it means that the model has been overfit to the validation data and you'll likely need to go back to the drawing board.
Dialogue: 0,0:16:23.32,0:16:30.69,Default,,0,0,0,,This is the number you would provide in a white paper or project report when asked about how the model performs on unseen data.
Dialogue: 0,0:16:30.71,0:16:33.91,Default,,0,0,0,,Once again, I'm pretty happy with the performance of this model.
Dialogue: 0,0:16:33.85,0:16:37.13,Default,,0,0,0,,I hope this helps you get started training your own neural network.
Dialogue: 0,0:16:37.12,0:16:43.35,Default,,0,0,0,,I know it's a lot to take in, but feel free to play around with some of the parameters and settings found in this example.
Dialogue: 0,0:16:43.34,0:16:51.64,Default,,0,0,0,,On the next episode, we'll convert our saved model file to a TensorFlow Lite model file and then deploy it on a Raspberry Pi.
Dialogue: 0,0:16:51.63,0:16:55.62,Default,,0,0,0,,This is the start of creating your very own Edge AI device
Dialogue: 0,0:16:55.75,0:16:57.03,Default,,0,0,0,,See you then.
